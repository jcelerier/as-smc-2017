
%=================================================================
\documentclass[applsci,article,submit,moreauthors,pdftex,10pt,a4paper]{mdpi}
%=================================================================
\firstpage{1} 
\makeatletter 
\setcounter{page}{\@firstpage} 
\makeatother 
\articlenumber{x}
\doinum{10.3390/------}
\pubvolume{xx}
\pubyear{2017}
\copyrightyear{2017}
\externaleditor{Academic Editor: name}
\history{Received: date; Accepted: date; Published: date}

%------------------------------------------------------------------
% The following line should be uncommented if the LaTeX file is uploaded to arXiv.org
%\pdfoutput=1

%=================================================================
% Add packages and commands here. The following packages are loaded in our class file: fontenc, calc, indentfirst, fancyhdr, graphicx, lastpage, ifthen, lineno, float, amsmath, setspace, enumitem, mathpazo, booktabs, titlesec, etoolbox, amsthm, hyphenat, natbib, hyperref, footmisc, geometry, caption, url, mdframed, tabto, soul, multirow, microtype, tikz


\usepackage{listings}
\usepackage{qtree}
\usepackage{tkz-graph}  
\usepackage{subcaption}
\usepackage{acronym}
\usetikzlibrary{shapes.geometric,positioning,fit,backgrounds}
%=================================================================
%% Please use the following mathematics environments: Theorem, Lemma, Corollary, Proposition, Characterization, Property, Problem, Example, ExamplesandDefinitions, Hypothesis, Remark, Definition
%% For proofs, please use the proof environment (the amsthm package is loaded by the MDPI class).

%=================================================================
% Full title of the paper (Capitalized)
\Title{A model for interactive media authoring}

% Author Orchid ID: enter ID or remove command
\newcommand{\orcidauthorA}{0000-0003-1253-298X} % Add \orcidA{} behind the author's name
%\newcommand{\orcidauthorB}{0000-0000-000-000X} % Add \orcidB{} behind the author's name

% Authors, for the paper (add full first names)
\Author{Jean-Michaël Celerier $^{1,\dagger,\ddagger}$\orcidA{}, Myriam Desainte-Catherine $^{1,\ddagger}$ and Bernard Serpette $^{2,}$*}

% Authors, for metadata in PDF
\AuthorNames{Jean-Michaël Celerier, Myriam Desainte-Catherine and Bernard Serpette}

% Affiliations / Addresses (Add [1] after \address if there is only one affiliation.)
\address{%
    $^{1}$ \quad Affiliation 1; e-mail@e-mail.com\\
    $^{2}$ \quad Affiliation 2; e-mail@e-mail.com}

% Contact information of the corresponding author
\corres{Correspondence: e-mail@e-mail.com; Tel.: +x-xxx-xxx-xxxx}

% Current address and/or shared authorship
\firstnote{Current address: Affiliation 3} 
\secondnote{These authors contributed equally to this work.}
% The commands \thirdnote{} till \eighthnote{} are available for further notes

% Simple summary
%\simplesumm{}

% Abstract (Do not insert blank lines, i.e. \\) 
\abstract{A single paragraph of about 200 words maximum. For research articles, abstracts should give a pertinent overview of the work. We strongly encourage authors to use the following style of structured abstracts, but without headings: 1) Background: Place the question addressed in a broad context and highlight the purpose of the study; 2) Methods: Describe briefly the main methods or treatments applied; 3) Results: Summarize the article's main findings; and 4) Conclusion: Indicate the main conclusions or interpretations. The abstract should be an objective representation of the article, it must not contain results which are not presented and substantiated in the main text and should not exaggerate the main conclusions.}

% Keywords
\keyword{interactive scores; intermedia; dataflow; patcher; i-score}

% The fields PACS, MSC, and JEL may be left empty or commented out if not applicable
%\PACS{J0101}
%\MSC{}
%\JEL{}


\featuredapplication{Authors are encouraged to provide a concise description of the specific application or a potential application of the work. This section is not mandatory.}

\acrodef{DAG}{Directed Acyclic Graph}

\newcommand\mg[1]{\ensuremath{ {\boldsymbol<} #1 {\boldsymbol>} }}
\DeclareMathOperator{\tc}{TC}
\DeclareMathOperator{\ic}{IC}
\DeclareMathOperator{\itv}{I}
\DeclareMathOperator{\proc}{P}
\title{A model for interactive media authoring}
\begin{document}

\section{Introduction}
Many music software fit in one of three categories: sequencers, patchers, and textual programming environments. Sequencers are used to describe temporal behaviours: an audio clip plays after another, while an automation curve changes an audio filter. Patchers are more commonly used to describe invariants: for instance specific audio filters, or compositional patterns. 

We propose in this paper a method that combines the sequencer and the patcher paradigm in a live system.  

The general approach is as follows: we first introduce a minimal model of the data we are operating on: namely, remote software or hardware such as OSC peripherals and sound cards. Then, two structures are presented: the first is a temporal structure, which allows to position events and processes relatively to each other, hierarchically, and in a timely fashion. The second is a graph structure akin to dataflows. This graph uses special connection types to take into account the fact that nodes of the graph might not always be active at the same time. Both structures are then combined: the state of the temporal processes is bound to the dataflow nodes. This combination is then expanded with specific implicit cases that are relevant in computer music workflows. These cases are described using structures wrapping the temporal and dataflow graphs. 

We compare the various models in the context of music creation: what entails using only the temporal structure, only the graph structure, and the combination of both. 

The latter model is shown to have enough expressive power to allow for recreation of common audio software logic within it: for instance traditional or looping audio sequencers. Additionnally, its use is presented in sample compositions: the first one is an example of audio editing, the second an interactive musical installation.

% Ce qui manque: déclaration de variables locales pour nommage ? Actuellement on utilise des variables globales si on veut un nom.

% => décrire requirements pour qu'un autre système de contraintes temporelles puisse fonctionner 
% => au minimum : enable / disable

%Pbq si on fait ça en fonctionnel: construction obligatoire en "top-down" ? on commence par les processus, puis les contraintes, etc. 
% sinon on doit parcourir tout pour remplacer ce qu'on veut

% TODO audio : plutôt que stocker du std::vector<std::vector<float>> pourquoi pas un gsl::span<gsl::span<float>>

% Sample accuracy pour audio ? on pourrait faire un tick par échantillon au prix de la performance. Mais pb avec PureData, etc. qui veulent 64 samples: il faudrait un mécanisme de buffering...
% Changements de vitesse: introduire des noeuds de "rescaling"  dès qu'on a deux objets qui sont en relation et peuvent avoir une vitesse différente. eg deux processus 
\subsection{State of the art}

There is a long-standing interest in the handling of time in programming languages, which is intrinsically linked to how the language handles dynamicity.

PEARL90\cite{halang2001safe}\footnote{Not to be mistaken with the Perl language commonly used for text processing} provides temporal primitives allowing for instance to perform loops at a given rate for a given amount of time.
More recently, Céu has been introduced as a synchronous language with temporal operators, and applications to multimedia\cite{Santos:2016:CLI:2976796.2976856}.

OpenMusic is a visual environment which allows to write music by functional composition.
It has been recently extended with timed sequences allowing to specify evolutions of parameters in time\cite{garcia:hal-01484077}.

Likewise, the Bach library for Max~\cite{agostini2015max} allows to define temporal variations of parameters during the playing of a note by with the mechanism of slots.
The processes controlled by such parameters are then available to use in the Max patch.

The Max for Live extension to Ableton Live allows to embed Max patches in the Ableton Live sequencer. 
Through the API provided, one can control the execution of various elements of the sequencer in Max; automations in Live can also be used to send data to Max patches at a given time.

A method for dynamic patching of Max abstractions based on CommonLisp has been proposed by Thomas Hummel\cite{hummel1994common} to reduce resource usage by enabling and disabling sub-patches at different points in the execution of a program.
This has the advantage of saving computing power for the active elements of the score.

Dataflows and especially synchronous dataflows have seen tremendous usage in the music and signal processing community. 
A list of patterns commonly used when developing dataflow-based music software is presented in~\cite{arumi2006dataflow}.
Formal semantics are given in~\cite{benveniste_data-flow_1993}.
Specific implementation aspects of dataflow systems are discussed in the Handbook of Signal Processing Systems\cite{bhattacharyya_handbook_2013}. 

Dynamicity in dataflows is generally separated in two independent aspects: dynamicity of the data, and of the topology.
The first relates to the variability on the streams of tokens, while the second is about changes to the structure of the graph. 
Boolean parametric dataflows\cite{bempelis2015boolean} have been proposed to solve dynamicity of topology, by introducing conditionals at the edges.

base: max, pd, séquenceurs: cubase/protools , live/bitwig...

openmusic

antescofo

inscore


\subsection{Context of this research}
This paper follows existing research on interactive scores, as part of the i-score project.
Previous research focused on operational semantics for interactive scores, based on time automatas\cite{arias2016authoring} or Petri nets\cite{allombert2007system}, mainly for software verification purposes. 
In contrast, we give here domain-centered functional semantics which models the current C++ implementation of the software.

We first define the temporal model, then extend it with a distinct data model which reads and produces the various inputs \& outputs of the system. 
Then, we introduce implicit operations and defaults in the context of a GUI software to create, modify, and playback such scores. These operations allow to simplify the usage of the paradigm for composers.
Real-world examples are provided and discussed.

\cite{celerier2017icmc}
\section{Orchestrated data}\label{sec.device}
We first define the data we operate on.
External devices are modeled as a tree of optional parameters.

Value parameters can have values of common data types such as integer, float, etc.
Audio parameters are arrays that contain either the current input audio buffers of the sound card or the buffers that will be written to the sound card's output.

The tree of nodes is akin to the methods and containers described in the OSC specification.

\begin{align*}
\mathbf{Value} & = \mathrm{Float} \mid \mathrm{Int} \mid \mathrm{Bool} \mid \mathrm{String} \mid \dots \\
\mathbf{ValueParameter} & = \mathrm{Value} \times \mathrm{Protocol} \\
\mathbf{AudioParameter} & = \mathrm{Float[][]} \times \mathrm{Protocol} \\
\mathbf{Parameter} & = \mathrm{ValueParameter} \mid \mathrm{AudioParameter} \\
\mathbf{Node} & = \mathrm{String} \times \mathrm{Maybe}~\mathrm{Parameter} \times \mathrm{Node[]} 
\end{align*}

Parameters and nodes bear additional metadata which is not relevant to describe here: textual description, tags, etc.

The parameters's associated values match the state of an external device: synthesizer, etc.
Multiple protocols are implemented to allow this: for instance OSC, MIDI, etc.

We define two core operations on parameters: 
\begin{align*}
\mathbf{pull} & : \mathrm{Parameter} \rightarrow \mathrm{Parameter} \\
              & (v, p) \mapsto (v', p)~\text{where v' is the last known value in the remote device}\\
\mathbf{push} &: \mathrm{Parameter} \times \mathrm{Value} \rightarrow \mathrm{Parameter} \\
              & (v, p), v' \mapsto (v', p)~\text{and v' is sent to the remote device} 
\end{align*}

\section{Temporal model}
The temporal model is twofold: it is a hierarchical tree of processes, whose durations and execution times are directed by intervals organized in a \ac{DAG}. 
The beginning and end of the intervals is subjected to various conditions that will be presented ; these conditions allow for various 
interactive behaviours. % TODO Processes are any kind of relevant artistic process: automations, notes sequences, sound files. 
In particular, specific dispositions of intervals and conditions are implemented as processes themselves, scenario and loop, which allows for hierarchy.

We note: $\tc$ for temporal conditions, $\ic$ for instantaneous conditions, $\itv$ for intervals, $\proc$ for processes. 
First, these elements are defined, then the semantics imposed on them by the scenario and the loop are presented.
These semantics allow both serial and parallel execution of musical processes.

\subsection{Data types}
\begin{figure}
    \centering
    \begin{subfigure}[t!]{0.45\textwidth}
        \centering
        \small\def\qtreeunaryht{2ex}
        \Tree [.interval
        [.scenario 
        [.interval~I_1 mapping ] 
        [.interval~I_2 [.loop [.interval automation ] ] ] 
        interval~I_3 
        [.interval~I_4 sound ] 
        [.interval~I_5 effect ]
        ] 
        !\qsetw{1mm}  automation sound  ]
        \caption{Hierarchical tree}
    \end{subfigure}

    \begin{subfigure}[t!]{0.45\textwidth}
        
        \centering
        \tikzstyle{VertexStyle}=[
        shape=ellipse,
        minimum width=6ex,
        draw
        ]
        
        \tikzstyle{EdgeStyle}=[
        ->,
        >=stealth'
        ]
        \tikzstyle{EditTimeSync}=[
        rounded corners=.15cm, 
        fill=gray!30, 
        draw=gray, 
        fill opacity=0.3
        ]
        \tikzstyle{WaitTimeSync}=[
        rounded corners=.15cm, 
        fill=orange!30, 
        draw=orange, 
        fill opacity=0.3
        ]
        
        \begin{tikzpicture} 
        \pgfdeclarelayer{box}
        \pgfdeclarelayer{text}
        \pgfsetlayers{box,text}
        \begin{pgfonlayer}{text}
        \SetGraphUnit{1.5} 
        \Vertex[L=$\ic_1$]{C1} \EA[L=$\itv_1$](C1){I1} \EA[L=$\ic_2$](I1){C2} \EA[L=$\itv_4$](C2){I4}
        \SO[L=$\ic_3$](C1){C3} \EA[L=$\itv_2$](C3){I2} \SOEA[L=$\ic_5$](I4){C5}
        \SOEA[L=$\itv_3$](C3){I3} \EA[L=$\ic_4$](I3){C4} \EA[L=$\itv_5$](C4){I5}
        
        \Edges(C1, I1, C2, I4, C5)
        \Edges(C3, I2, C2)
        \Edges(C4, I5, C5)
        \Edges(C3, I3, C4)
        \end{pgfonlayer}
        
        \begin{pgfonlayer}{box}
        \node[fit=(C1) (C3), EditTimeSync, label=above:$\tc_1$] {};
        \node[fit=(C2), EditTimeSync, label=above:$\tc_2$] {};
        \node[fit=(C4), EditTimeSync, label=above:$\tc_3$] {};
        \node[fit=(C5), EditTimeSync, label=above:$\tc_4$] {};
        \end{pgfonlayer}
        \end{tikzpicture}
        
        \caption{Temporal DAG}
    \end{subfigure}
\end{figure}
% TODO représenter trace d'exécution
    
    
\subsubsection{Conditions and expressions}
We first define the conditional operations we want to be able to express.
We restrain ourselves to simple propositional logic operands: \textbf{and}, \textbf{or}, \textbf{not}.

Expressions operate on addresses and values of the device tree presented in \ref{sec.device}.

Formally, expressions are defined as a tree:
Let \textbf{Comparator} be an identifier for standard value comparison operations: $<, \leq, >, \geq, =, \neq$ and \textbf{Operator} standard logical operators \textbf{and} \&  \textbf{or}.

\begin{align*}
    \mathbf{Atom} & :  (\mathrm{Parameter} \mid \mathrm{Value}) \times (\mathrm{Parameter} \mid \mathrm{Value}) \times \mathrm{Comparator} \\
    \mathbf{Negation} & : \mathrm{Expression} \\
    \mathbf{Composition} & : \mathrm{Expression} \times \mathrm{Expression} \times \mathrm{Operator} \\
    \mathbf{Impulse} & : \mathrm{Parameter} \times \mathrm{Bool} \\
    \mathbf{Expression} &: \mathrm{Atom} \mid \mathrm{Negation} \mid \mathrm{Composition} \mid \mathrm{Impulse}
\end{align*}

Two operations are defined on expressions and the data types that compose them: 

\begin{itemize}
    \item $\mathbf{update}: \mathrm{Expression} \rightarrow \mathrm{Expression}$. Used to reset any internal state and query up-to-date values for the expressions. For instance, $\mathbf{update}$ on an $\mathbf{Atom}$ fetches if possible new values for the parameters, why may include network requests.
    
    Precisely:
    \[
    \begin{cases}
    \mathrm{update} : & \mathrm{Composition} \rightarrow \mathrm{Composition} \\ 
    & (e_1, e_2, o) \mapsto (\mathrm{update}~e_1, \mathrm{update}~e_2, o) \\
    \mathrm{update} : & \mathrm{Negation} \rightarrow \mathrm{Negation} \\
    &  e_1 \mapsto \mathrm{update}~ e_1 \\
    \mathrm{update} :&  \mathrm{Atom} \rightarrow \mathrm{Atom} \\
    & \begin{cases}
    (\mathrm{parameter}~p_1, \mathrm{parameter}~p_2, o) \mapsto (\mathrm{pull}~p_1, \mathrm{pull}~p_2, o) \\
    (\mathrm{parameter}~p_1, \mathrm{value}~v_2, o) \mapsto (\mathrm{pull}~p_1, v_2, o) \\ 
    \dots
    \end{cases}\\
    \mathrm{update} : & \mathrm{Impulse} \rightarrow \mathrm{Impulse} \\
    & (p, b) \mapsto (p, \mathrm{false})
    \end{cases}
    \] 
        
    \item $\mathbf{evaluate}: \mathrm{Expression} \rightarrow \mathrm{Bool}$. Performs the actual logical expression evaluation, according to the expected logical rules.
     % TODO spécifier correctement Pulse
\end{itemize}

\begin{itemize}
    \item An atom is a comparison between two parameters, a parameter and a value, or two values.
    \item Negations and compositions are the traditional predicate logic building blocks.
    \item We introduce a specific operator, ``impulse'', which allows to decide whether a message was received in a given time span.
\end{itemize}

\subsubsection{Temporal processes}
Temporal processes are executed by intervals at each tick. 
The actual processes will be defined in sections~, \ref{sec.scenario}, \ref{sec.loop}, \ref{sec.datamodel}.

A process is a type $\proc$ associated with the following operations: 
\begin{align*}
\mathbf{start}&: \proc \rightarrow \proc \\
\mathbf{stop}&: \proc \rightarrow \proc \\
\mathbf{tick}&: \proc * \mathbb{Z} * \mathbb{Z} * \mathbb{R} \rightarrow P\\
\mathbf{Process}&: \mathrm{Scenario} \mid \mathrm{Loop} \mid  \dots
\end{align*}
\subsubsection{Interval}
We want to be able to express the passing of time, for a given duration.
This duration may or may not be finite.

A duration is defined as a positive integer.
An interval is at its core a set of durations: a min, an optional max, and the current position. 
The lack of max means infinity.
An interval is said to be fixed when its min equals its max. It may be enabled or disabled.
\begin{align*}
\mathbf{Status} &= \mathrm{Waiting} \mid \mathrm{Pending} \mid \mathrm{Happened} \mid \mathrm{Disposed} \\
\mathbf{Interval} &= \mathrm{Duration} \times \mathrm{Maybe} ~\mathrm{Duration} \times \mathrm{Duration} \times \mathrm{Status}
\end{align*}

The time scale is not specified by the system: for instance, when working with audio data it may be better to use the audio sample as a base unit of time.
But many applications don't use the audio rate: when working purely with visuals it may be better to use the screen refresh rate as time base in order not to 
waste computer resources and energy. 

\subsubsection{Instantaneous condition}
Then, we want to be able to enable or disable events and intervals according to a condition, given in the expression language seen in \ref{sec.temporal.conditions}. An instantaneous condition is defined as follows: 

\[
\mathbf{Condition} = \mathrm{Expression} \times \mathrm{Interval}[] \times \mathrm{Interval}[] \times \mathrm{Status}
\]

It is preceded and followed by a set of intervals.

Expressions are disabled either when they are false or when they are preceded by a non-null number of intervals, all of them already disabled through other conditions. This propagates recursiveley to the following intervals and conditions. 

\subsubsection{Temporal condition}
A temporal condition is used to synchronize starts and ends of intervals, while allowing to implement behaviours such as : ``start the chorus when the fader is at 0''.

Temporal conditions carry instantaneous conditions, which will be evaluated at the moment where the temporal condition becomes true.

\paragraph{A note on asynchronicity}
We consider here a synchronous version of the temporal conditions, which assumes that external values would not variate at a greater rate than the tick rate of the system; in practice this is generally not the case. Hence, the actual implementation of temporal conditions supports asynchronous updates of the condition value according to received network messages rather than the tick rate. 
This means that the execution will not miss cases where a condition would become false, true, then false again after the beginning and before the end of a tick.

\subsubsection{Operations}
\begin{lstlisting}


type process = 
NodeProcess of nodeProcess | Scenario of scenario | Loop of loop
and interval = {
minDuration:duration;
maxDuration : duration option;
nominalDuration : duration;
itvStatus: status;
processes: process list
}
and condition = { 
condExpr: expression; 
previousItv: interval list; 
nextItv: interval list; 
status: status; 
}
and temporalCondition = { 
syncExpr: expression; 
conds: condition list
}
and scenario = { 
intervals: interval list ; 
triggers: temporalCondition list; 
}
and loop = { 
pattern: interval; 
startTrig: temporalCondition;
endTrig: temporalCondition; 
};;

\end{lstlisting}
% TODO ici on push en front, tandis qu'en C++ on push en back
\begin{lstlisting}
add_process interval proc: interval * proc -> interval
 (t1, t2, p, t3) -> (t1, t2, proc::p, t3)
\end{lstlisting}

\begin{lstlisting}
add_event tc ic: TemporalCond * InstCond -> TemporalCond
 (..., ics, ...) -> (..., ic::ics, ...)
\end{lstlisting}

exécution : 

interval: 

On retourne une fonction ... \lstinline|graph_fun| va être appliquée au graph. Faut-il avoir une liste explicite ou bien juste passer le graph et demander à chaque fonction d'appliquer ses fonctions enfants ? Le second fait plus fonctionnel mais le premier laisse moins de marge d'erreur (DRY)
\begin{lstlisting}
get_node graph node_id -> node
update_node graph node_id node -> graph

graph_fun: graph -> graph ; va transformer un noeud du graphe d'une maniere donnee

tuple_first tpls: retourne les premiers elements d'une liste de paires
tuple_second tpls: retourne les premiers elements d'une liste de paires

tick: itv, count, offset : interval * duration * duration -> interval * graph_fun[]
  ((..., nom, t, pos, procs), new_date) -> (
  let procs = map procs (state _ t offset) in 
    (..., t + count, t + count / nom, tuple_first procs ),  
    fun (node_date,node_offset) -> (t+count, offset) :: tuple_second procs)

\end{lstlisting}

processes:
\begin{lstlisting}
  state: process * t -> process * graph_fun
  
  described for each process (polymorphic)
\end{lstlisting}

\subsection{Temporal graph: scenario}\label{sec.scenario}


\subsubsection{Creational operations}

\begin{lstlisting}
add_interval sc itv sev eev
\end{lstlisting}
\begin{lstlisting}
add_sync sc
\end{lstlisting}
\subsubsection{Execution operations}

\begin{lstlisting}
process_event:
\end{lstlisting}
\begin{lstlisting}
make_happen:
\end{lstlisting}
\begin{lstlisting}
make_dispose:
\end{lstlisting}

\begin{lstlisting}
scenario_state : scenario -> scenario * state
\end{lstlisting}

\subsection{Loop}\label{sec.loop}
Pbq: not introducing cycles in the temporal graph
\begin{lstlisting}
process_event:
\end{lstlisting}
\begin{lstlisting}
make_happen:
\end{lstlisting}
\begin{lstlisting}
make_dispose:
\end{lstlisting}
\begin{lstlisting}
loop_state:
\end{lstlisting}
\section{Data model}\label{sec.datamodel}
=> set date
=> set offset pour offset audio (p-ê pas nécessaire si on fait comme LAStream)

\section{Data graph}
Questions: 
* node ordering
* port definitions

\begin{lstlisting}

(* ports *)
type edgeType = Glutton | Strict | Delayed ;;
type edge = { edgeId: int; source: int; sink: int; edgeType: edgeType; } 
and audioPort = { audioPortId: int; audioPortAddr: audioParameter option; audioEdges: edge list } 
and valuePort = { valuePortId: int; valuePortAddr: valueParameter option; valueEdges: edge list } 
and port = AudioPort of audioPort | ValuePort of valuePort
;;

\end{lstlisting}

\subsection{Structures}

\begin{lstlisting}

(* curves *)
type curve = (float * float) list ;;
let value_at curve x = 0.0;;

(* some processes *)
type automation = valuePort * curve;;
type mapping = valuePort * valuePort * curve;;
type sound = audioPort * float array array;;
type passthrough = audioPort * valuePort * audioPort * valuePort;;

type dataNode = Automation of automation | Mapping of mapping | Sound of sound | Passthrough of passthrough ;;
type grNode = { nodeId: int; data: dataNode; enabled: bool; date: duration; position: position; };;


type graph = { nodes: grNode list ; edges: edge list; };;

let next_id lst f = 1 + (List.fold_left max 0 (List.map f lst));;
let next_node_id lst = next_id lst (fun n -> n.nodeId);;
let next_edge_id lst = next_id lst (fun n -> n.edgeId);;

let create_audio_port = { audioPortId = 0; audioPortAddr = None; audioEdges = []; } ;;
let create_value_port = { valuePortId = 0; valuePortAddr = None; valueEdges = []; } ;;
let test_edge = { edgeId = 33; source = 4; sink = 5; edgeType = Glutton; };;
let some_sound_data = Array.make 2 (Array.make 8 0.);; 
let some_sound = Sound (create_audio_port, some_sound_data);;

let some_passthrough = Passthrough ( create_audio_port, create_value_port, create_audio_port, create_value_port );;

(* test *)
let test_node_1 = { nodeId = 1; data = some_sound; enabled = false; date = 0; position = 0. };;
let test_node_2 = { nodeId = 34; data = some_sound; enabled = false; date = 0; position = 0. };;
next_node_id [ test_node_1; test_node_2 ] ;;   

let create_graph = { nodes = []; edges = [] };;
let add_node gr nodeDat = 
let new_id = next_node_id gr.nodes in 
let newNodeDat = match nodeDat with 
| Automation a -> nodeDat
| Mapping m -> nodeDat
| Sound s -> nodeDat
| Passthrough p -> nodeDat
in
let new_node = { nodeId = new_id; data = newNodeDat; enabled = false; date = 0; position = 0. } in
(new_node, {nodes = new_node::gr.nodes; edges = gr.edges})
;;
let add_edge gr src snk t = 
let new_id = next_edge_id gr.edges in 
let new_edge = { edgeId = new_id; source = src; sink = snk; edgeType = t } in 
(new_edge, { nodes = gr.nodes; edges = new_edge::gr.edges })
;;

(* test *)
let test_g = create_graph;;
let (snd1, test_g) = add_node test_g some_sound;;
let (snd2, test_g) = add_node test_g some_sound;;
let (p1, test_g) = add_node test_g some_passthrough;;

(* let (e1, test_g) = add_edge snd1. *)


type nodeProcess = { 
node: int; 
curTime: duration; 
curOffset: duration;
curPos: position;    
};;






node: enabled * executed * time * position * inlets * outlets * priority
add_node graph 
connect graph node node edge
enable graph node
disable graph node

\end{lstlisting}
\subsection{Operations}
Input mix on each port

\begin{lstlisting}
copy_from_global
copy_from_local
init_node
teardown_node


\end{lstlisting} 


\subsection{Tick description}

General flow: 

disable strict nodes

sort remaining nodes according to the custom order chosen (default, temporal, custom)

priority: 
* explicit cables
* local or global address

do a tick: 

\begin{lstlisting}
let clear_outputs n = 
  (_, ..., (map n.outputs (match p with 
  | value -> clear value
  | audio -> clear audio
))

let pull_port p : port -> port 

init_value : port -> value
let init_value value_port = 
  if !empty value_port.cables
    mix (pull_port value_port.cables)
  pull value_port.address


let init_node g n = 
  (_, (map n.inputs (match p with 
    | value -> pull value
  )), ...) 
exec_node: 
   in
  let copy_inputs n = 
  let init_node n = 
    copy_inputs clear_outputs n      
  in 
  
  new_node, new_local_state = exec_node init_node n
  replace g n new_node 
    
tick_graph: 
  while: ! empty nodes 
  
\end{lstlisting}



\subsection{Data nodes}
\subsubsection{Passthrough}
-> used for scenario and interval
-> mixing at the input


\subsubsection{Automation}
\paragraph{Curves}
start point + set of (segment * breakpoint)

curve + message output port
$x\in[0;1]$ -> in the nominal duration of the parent time interval.

\begin{lstlisting}
state_autom :
\end{lstlisting}
\subsubsection{Mapping}
message input port + curve + message output port
\begin{lstlisting}
state_mapping :
\end{lstlisting}
\subsubsection{JavaScript}
n message input port + curve + n message output port
\begin{lstlisting}
state_js :
\end{lstlisting}
\subsubsection{Piano Roll}
notes + midi output port
\begin{lstlisting}
state_midi :
\end{lstlisting}
\subsubsection{Sound file}
sound data + midi output port
\begin{lstlisting}
state_sndfile :
\end{lstlisting}
\subsubsection{Buffer}
Used to keep audio input in memory

Why isn't the delay cable not enough ? can't go backwards. 
pb: pauser au milieu: coupure. cas dans les boucles: on réécrit par dessus (buffer vidé sur start).
\begin{lstlisting}
state_buffer :
\end{lstlisting}
%\subsubsection{Shader}
%\subsubsection{3D model}
%gltf ? 

\section{Combined model}
-> on ajoute node aux tc

-> nodeprocess fait le lien entre graphnode et time process, permet de faire l'activation et l'écoulement du temps

-> offset nécessaire pour tc pour gérer l'audio (mais pourrait être ajouté dans le modèle de base. Ou bien passer une paire de pointeurs.. ? )

\subsection{Combined tick}
Exécution complète d'un tick: 
Copy audio buffers and input data, execute the temporal tick, execute the graph tick, copy the output audio buffer and apply the produced state by pushing the values.

Pour être propre, il faudrait faire un "pull" général au début...
\begin{figure}
	\caption{General data flow for a tick}
\end{figure}

\section{Proposed sequencer behaviour}
Conditions et cie: The most common case for an expression is to be true.

UI: création automatique de liens implicites des enfants vers les parents
=> "cable créé par défaut" quand on rajoute un processus dont on marque l'entrée

=> pour toute contrainte, pour tout scénario, créer noeud qui fait le mixage
=> création d'objets récursivement, etc

- Problème des states dans scénario ?
=> states du scénario: comment interviennent-ils ? faire un scénario fantôme 


- Mettre l'accent sur la recréation de la sémantique de i-score à partir du graphe: 
=> messages: actuellement "peu" typés ; rajouter type de l'unité ? 

=> pbq du multicanal: pour l'instant non traitée, on ne gère que les cas mono / stereo pour le upmix / downmix
Choix pour multicanal: faire comme jamoma avec objets tilde
=> sliders et dispatching de canaux ?
=> cables: rubberband ? il faut mettre un rubberband dès qu'on a une entrée et une sortie qui n'ont pas la même vitesse relative. Dire que pour les automations ça interpole de manière naturelle avec le ralentissement et l'accélération (on sépare vitesse et granularité)


- Dire qu'on pourrait affiner en combinant plus précisément les "sous-ticks" temporels et de données
pour que par exemple la production d'un état dans un scénario entraîne une condition dans un autre scénario


\section{Applications and examples}

\subsection{Reconstructing existing paradigms}
In this part we give example of reconstruction of standard audio software behaviours with the given model.
\subsubsection{Audio sequencer}
Notable software in this category includes Steinberg Cubase, Avid Pro Tools, \dots

The common metaphor for audio sequencers is the track, inspired from mixing desks and tape recorders. 
We will take the example of audio and midi tracks. 
Such an audio sequencer can be modeled by : 

\begin{itemize}
    \item A root: an infinite interval.
    \item This interval contains two processes: a scenario and an effect bus. 
    The sound output of the scenario goes to the input of the effect bus.
    \item The scenario contains the actual tracks.
    \item These tracks are also modeled by infinite constraints.
\end{itemize}

We divide the tracks in two categories.
Audio tracks are built with : 
\begin{itemize}
  \item A scenario with a single sequence of intervals, some of which may bear sound file processes and others being empty.
  \item An effect bus process. The output of the scenario goes to the input of the effect bus. Generally, this effect bus would end by channel operations such as panning and volume adjustment, in a similar fashion to mixing desks.
\end{itemize} 

Midi tracks are built with : 
\begin{itemize}
    \item A scenario with a single sequence of intervals, some of which may bear MIDI notes processes and others being empty.
    \item An instrument process, which takes MIDI data and outputs sound.
    \item Like before, an effect bus applied to the instrument's output.
\end{itemize}

This can easily be extended with further features: sends, automations, etc.
\subsubsection{Looping audio sequencer}
More recently, a different kind of sequencer has emerged: the looping, non-linear sequencer. 
The prime exemple of this is Ableton Live. We give the example for a simplified model of live-looping without quantization.

These sequencers are also organized in tracks ; however, within a track, the musician can choose a single loop 
that is currently playing, and regularly switch the current loop.

Hence, the general organization stays the same than for the audio sequencer: most importantly, the way effect buses are applied does not change.

\begin{itemize}
    \item Each clip of a track is given an index. 
    \item Each track also has a parameter which is the next clip to play, \lstinline|next_clip|. These parameters can be introduced as variables in the device tree.
    \item We replace the scenarios containing the actual sound files or midi notes by loop processes. 
    \item The loops processes are defined with and ending temporal condition. 
    \item Inside the loop pattern, there is a single scenario process. This scenario process has a set of parallel intervals, each with one sound file. Every interval begins with an instantaneous condition that compares the \lstinline|next_clip| parameter to the current clip's index. Hence, at most one clip is playing at the same time in each track. If the \lstinline|next_clip| does not change the track keeps looping on the sound file.
\end{itemize}

Extension: par ex. dans une boucle on peut mettre un autre scénario.
Pb : tic qui manque. On peut y remédier en exécutant le trigger "en avance".
\subsubsection{Patcher}


\subsection{Musical examples}
\subsubsection{Audio compositing}
-> on utilise un scénario qui lit des parties d'une entrée son dans différents bus d'effets. L'effet peut se déclencher en retard.

Org: 

Intervalle racine

Process 1:  Audio input
Process 2 : Scenario
  -> Trois itv ; entrée reliée strict à sortie de audio input ; sortie dans parent
  
Process 3 : FX
Process 4 : scenario
Audio Input -> itv {1,2,3} -> scenario -> fx -> scenario

\subsubsection{Musical carousel}
We present here a real-world interactive music example: the musical carousel.
Each seat on the carousel has different instrument-like input devices: reactive pads, motion sensors, etc.
A run in the carousel generally operates as follows: 

\begin{itemize}
    \item The first few seconds, the rules of the carousel are explained to the participants.
    \item The song starts: the passengers can start interacting with their instruments. An overall music is generated from their interpretation. Played notes stay in predefinite scales which may vary over time; pre-recorded parts can also be layered on top. The overall song structure can vary according to the intensity of the played music: for instance, if everyone plays \textit{piano}, different instruments may become available in the next section of the song, a part may be shorter or longer, etc. Such variations are written by the composer for each song.
    \item At the end of the song, the participants hear a summarized version of the song they just played. This version also has additional corrections and adjustments applied algorithmically.
\end{itemize}

- Réutilisation des données d'entrée: scores sur certaines parties ; réutilisation de certaines notes et des pics d'intensité -> nécessite d/dx
- Gammes: filtrage global du MIDI In

\subsection{Notes on implementation}


=> "third gen" audio sequencer.
first gen: cubase, etc
second gen: non-linear: ableton, bitwig
third gen: entirely interactive: i-score, iannix. what else ? 

reproducibilité: code source dispo
\section{Evaluation and Discussion}
Enforcing graph constraints: mostly done through UI. For instance: ic are created on tc, etc. No "going back" which would break DAG-ness.

Faire parenthèse sur domain driven design sur logiciels de musique qui fournit de meilleurs résultats que application directe de modèles existants (petri, etc).
Peut-être donner un méta-modèle qui correspond à nos structures ?

Dire pourquoi un tic est introduit lors d'une interaction (notamment, permet de ne pas avoir de "boucle infinie" si on a une boucle de durée 0 avec deux triggers vrais) ; est aussi plus cohérent pour les utilisateurs pour qui une interaction doit être manifeste.

Avantage: manipulation uniforme des processus, que ce soit des automations, des groupes, des fichiers sons, etc.
\section{Conclusion}

missing: quantification

missing: sound speed

\supplementary{The following are available online at www.mdpi.com/link, Figure S1: title, Table S1: title, Video S1: title.}

\acknowledgments{
    Blue Yeti, ANRT, SCRIME 
    All sources of funding of the study should be disclosed. Please clearly indicate grants that you have received in support of your research work. Clearly state if you received funds for covering the costs to publish in open access.}

\authorcontributions{For research articles with several authors, a short paragraph specifying their individual contributions must be provided. The following statements should be used ``X.X. and Y.Y. conceived and designed the experiments; X.X. performed the experiments; X.X. and Y.Y. analyzed the data; W.W. contributed reagents/materials/analysis tools; Y.Y. wrote the paper.'' Authorship must be limited to those who have contributed substantially to the work reported.}

\conflictsofinterest{The authors declare no conflict of interest. The founding sponsors had no role in the design of the study; in the collection, analyses, or interpretation of data; in the writing of the manuscript, and in the decision to publish the results.} 

\externalbibliography{yes}
\bibliography{biblio}

\end{document}